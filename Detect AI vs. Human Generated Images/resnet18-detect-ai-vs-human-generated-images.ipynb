{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":91198,"databundleVersionId":10884264,"sourceType":"competition"},{"sourceId":10550636,"sourceType":"datasetVersion","datasetId":6412205}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms, models\nfrom torch import tensor\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nfrom PIL import Image\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T22:26:28.499182Z","iopub.execute_input":"2025-02-21T22:26:28.499522Z","iopub.status.idle":"2025-02-21T22:26:35.081374Z","shell.execute_reply.started":"2025-02-21T22:26:28.499495Z","shell.execute_reply":"2025-02-21T22:26:35.080447Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Load and Prepare the Dataset","metadata":{}},{"cell_type":"markdown","source":"### Load the CSV files","metadata":{}},{"cell_type":"code","source":"# Define the root directory of the dataset\ndataset_root = '/kaggle/input/ai-vs-human-generated-dataset/'\n# Load the train CSV file\ntrain_df = pd.read_csv(os.path.join(dataset_root, 'train.csv'))\n# Load the test CSV file\ntest_df = pd.read_csv(os.path.join(dataset_root, 'test.csv'))\n\n# Split into training and validation (80% train, 20% validation)\ntrain_df, val_df = train_test_split(train_df, test_size=0.2, random_state=42, stratify=train_df['label'])\n\nprint(f\"Train size: {len(train_df)}, Validation size: {len(val_df)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T22:26:35.082492Z","iopub.execute_input":"2025-02-21T22:26:35.082938Z","iopub.status.idle":"2025-02-21T22:26:35.261097Z","shell.execute_reply.started":"2025-02-21T22:26:35.082908Z","shell.execute_reply":"2025-02-21T22:26:35.260063Z"}},"outputs":[{"name":"stdout","text":"Train size: 63960, Validation size: 15990\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### Define a custom Dataset classes","metadata":{}},{"cell_type":"code","source":"# Define the custom Dataset class\nclass ImageDataset(Dataset):\n    def __init__(self, df, root_dir, transform=None):\n        self.df = df\n        self.root_dir = root_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.root_dir, self.df.iloc[idx, 1])  # Use the path directly from CSV\n        image = Image.open(img_path).convert('RGB')\n        label = int(self.df.iloc[idx, 2])  # Convert label to integer\n        label = tensor(label, dtype=torch.long)  # Convert to PyTorch tensor\n        if self.transform:\n            image = self.transform(image)\n        return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T22:26:35.262773Z","iopub.execute_input":"2025-02-21T22:26:35.263025Z","iopub.status.idle":"2025-02-21T22:26:35.268767Z","shell.execute_reply.started":"2025-02-21T22:26:35.263003Z","shell.execute_reply":"2025-02-21T22:26:35.268030Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class TestImageDataset(Dataset):\n    def __init__(self, df, root_dir, transform=None):\n        self.df = df\n        self.root_dir = root_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        img_name = self.df.iloc[idx, 0]  # Get file name\n        img_path = os.path.join(self.root_dir, self.df.iloc[idx, 0])  # Use the first column (id/file_name)\n        image = Image.open(img_path).convert('RGB')\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, img_name  # Return file name along with image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T22:26:35.269907Z","iopub.execute_input":"2025-02-21T22:26:35.270188Z","iopub.status.idle":"2025-02-21T22:26:35.285375Z","shell.execute_reply.started":"2025-02-21T22:26:35.270169Z","shell.execute_reply":"2025-02-21T22:26:35.284680Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### Define transformations","metadata":{}},{"cell_type":"code","source":"# Define transformations\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T22:26:35.286036Z","iopub.execute_input":"2025-02-21T22:26:35.286305Z","iopub.status.idle":"2025-02-21T22:26:35.302923Z","shell.execute_reply.started":"2025-02-21T22:26:35.286285Z","shell.execute_reply":"2025-02-21T22:26:35.302214Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"### Create datasets and dataloaders","metadata":{}},{"cell_type":"code","source":"train_dataset = ImageDataset(train_df, dataset_root, transform=transform)\nval_dataset = ImageDataset(val_df, dataset_root, transform=transform)\ntest_dataset = TestImageDataset(test_df, dataset_root, transform=transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\ntest_loader =  DataLoader(test_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T22:26:35.303583Z","iopub.execute_input":"2025-02-21T22:26:35.303816Z","iopub.status.idle":"2025-02-21T22:26:35.318127Z","shell.execute_reply.started":"2025-02-21T22:26:35.303796Z","shell.execute_reply":"2025-02-21T22:26:35.317345Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Define the Model","metadata":{}},{"cell_type":"markdown","source":"### Load a pre-trained model (e.g., ResNet18) and modify the final layer","metadata":{}},{"cell_type":"code","source":"from torchvision.models import ResNet18_Weights\nmodel = models.resnet18(weights=ResNet18_Weights.DEFAULT)\nmodel.fc = nn.Linear(model.fc.in_features, 2)  # 2 classes: AI-generated and human-created","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T22:26:35.318931Z","iopub.execute_input":"2025-02-21T22:26:35.319210Z","iopub.status.idle":"2025-02-21T22:26:36.287230Z","shell.execute_reply.started":"2025-02-21T22:26:35.319189Z","shell.execute_reply":"2025-02-21T22:26:36.286372Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 76.7MB/s]\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Freeze early layers (optional)\nfor param in model.parameters():\n    param.requires_grad = False  # Freeze all layers\nfor param in model.fc.parameters():\n    param.requires_grad = True  # Unfreeze the final layer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T22:26:36.289039Z","iopub.execute_input":"2025-02-21T22:26:36.289274Z","iopub.status.idle":"2025-02-21T22:26:36.293466Z","shell.execute_reply.started":"2025-02-21T22:26:36.289254Z","shell.execute_reply":"2025-02-21T22:26:36.292512Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"### Move the model to the GPU if available","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T22:26:36.294275Z","iopub.execute_input":"2025-02-21T22:26:36.294578Z","iopub.status.idle":"2025-02-21T22:26:36.615571Z","shell.execute_reply.started":"2025-02-21T22:26:36.294548Z","shell.execute_reply":"2025-02-21T22:26:36.614868Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# Define Loss Function and Optimizer","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T22:26:36.616440Z","iopub.execute_input":"2025-02-21T22:26:36.616799Z","iopub.status.idle":"2025-02-21T22:26:36.621217Z","shell.execute_reply.started":"2025-02-21T22:26:36.616734Z","shell.execute_reply":"2025-02-21T22:26:36.620292Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# Train the Model","metadata":{}},{"cell_type":"code","source":"num_epochs = 5  \n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    \n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item()\n    # Validation phase\n    model.eval()\n    val_correct = 0\n    val_total = 0\n\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, predicted = torch.max(outputs, 1)\n            val_correct += (predicted == labels).sum().item()\n            val_total += labels.size(0)\n\n    val_accuracy = 100 * val_correct / val_total\n\n    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}, Validation Accuracy: {val_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T22:26:36.622148Z","iopub.execute_input":"2025-02-21T22:26:36.622412Z","iopub.status.idle":"2025-02-21T23:24:25.076406Z","shell.execute_reply.started":"2025-02-21T22:26:36.622392Z","shell.execute_reply":"2025-02-21T23:24:25.075468Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5, Loss: 0.3034, Validation Accuracy: 88.35%\nEpoch 2/5, Loss: 0.2632, Validation Accuracy: 90.95%\nEpoch 3/5, Loss: 0.2628, Validation Accuracy: 90.61%\nEpoch 4/5, Loss: 0.2552, Validation Accuracy: 89.92%\nEpoch 5/5, Loss: 0.2564, Validation Accuracy: 90.13%\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"# Evaluate the Model","metadata":{}},{"cell_type":"code","source":"# Make predictions on test set\nmodel.eval()\npredictions = []\n\nwith torch.no_grad():\n    for images, _ in test_loader:  # Ignore labels if they exist in the dataset\n        images = images.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs, 1)\n        predictions.extend(predicted.cpu().numpy())\n\n# Ensure IDs are correctly extracted from test_df\nsubmission_df = pd.DataFrame({'id': test_df['id'], 'label': predictions})\n\n# Save predictions to CSV\nsubmission_df.to_csv('submission.csv', index=False)\n\n# Check the first few rows\nprint(submission_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T23:27:15.147887Z","iopub.execute_input":"2025-02-21T23:27:15.148224Z","iopub.status.idle":"2025-02-21T23:30:42.749633Z","shell.execute_reply.started":"2025-02-21T23:27:15.148194Z","shell.execute_reply":"2025-02-21T23:30:42.748710Z"}},"outputs":[{"name":"stdout","text":"                                                  id  label\n0  test_data_v2/1a2d9fd3e21b4266aea1f66b30aed157.jpg      0\n1  test_data_v2/ab5df8f441fe4fbf9dc9c6baae699dc7.jpg      1\n2  test_data_v2/eb364dd2dfe34feda0e52466b7ce7956.jpg      0\n3  test_data_v2/f76c2580e9644d85a741a42c6f6b39c0.jpg      0\n4  test_data_v2/a16495c578b7494683805484ca27cf9f.jpg      0\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}